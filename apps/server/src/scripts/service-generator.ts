/* eslint-disable no-console */

import { getDMMF } from "@prisma/sdk";
import fs from "node:fs";
import path from "node:path";

async function getRelationships(models: any) {
  const modelNames = new Set(models.map((m: any) => m.name));
  const relationships: any[] = [];

  models.forEach((model: any) => {
    model.fields.forEach((field: any) => {
      if (field.name.endsWith("Id")) {
        const targetName = field.name.slice(0, -2);
        const guessedTarget = [...modelNames].find(
          (name: any) => name.toLowerCase() === targetName.toLowerCase(),
        );
        if (guessedTarget) {
          relationships.push({
            model: model.name,
            field: field.name,
            target: guessedTarget,
          });
        }
      }
    });
  });

  return relationships;
}

export async function getModels() {
  const schemaPath = path.resolve(__dirname, "../../prisma/schema.prisma");

  if (!fs.existsSync(schemaPath)) {
    throw new Error(`schema.prisma not found at: ${schemaPath}`);
  }

  const datamodel = fs.readFileSync(schemaPath, "utf-8");
  const dmmf = await getDMMF({ datamodel });
  return dmmf.datamodel.models;
}

async function generateValidations(model: any) {
  const lines: string[] = [];

  model.fields.forEach((field: any) => {
    if (
      field.kind === "scalar"
      && field.isRequired
      && !field.isId
      && field.name !== "createdAt"
      && field.name !== "updatedAt"
    ) {
      lines.push(
        `if (!entity.${field.name}) throw new BadRequestError("${field.name} is required");`,
      );
    }
  });

  return lines.map(line => `\t\t${line}`).join("\n");
}

function getTimestampComment(): string {
  return `// This file was generated by generate-services.ts`;
}

function extractCommentAndBody(content: string) {
  const lines = content.split("\n");
  if (
    lines[0]?.startsWith(
      "// This file was generated by generate-services.ts",
    )
  ) {
    return {
      comment: lines[0],
      body: lines.slice(1).join("\n").trim(),
    };
  }
  return {
    comment: null,
    body: content.trim(),
  };
}

function toKebabCase(str: string) {
  return str
    .replace(/([a-z0-9])([A-Z])/g, "$1-$2")
    .replace(/([A-Z])([A-Z][a-z])/g, "$1-$2")
    .toLowerCase();
}

async function generateServiceFiles(models: any, relationships: any) {
  const directory = path.resolve(__dirname, "../services/repository");
  fs.mkdirSync(directory, { recursive: true });

  for (const model of models) {
    const kebabName = toKebabCase(model.name);
    const serviceFile = path.resolve(directory, `${kebabName}.service.ts`);
    const validations = await generateValidations(model);

    const newBody = `import { ${model.name} } from "@prisma/client";
import { BaseService } from "./_base.service";
import { prisma } from "@/utils/prisma";
import { BadRequestError } from "@/middleware/error.middleware";

type ${model.name}Attributes = Omit<${model.name}, "id" | "createdAt" | "updatedAt">;

export class ${model.name}Service extends BaseService<${model.name}> {
\tprotected model = prisma.${model.name.charAt(0).toLowerCase() + model.name.slice(1)};
\tprotected entityName = "${model.name}";
\tprotected modelName = "${model.name.charAt(0).toLowerCase() + model.name.slice(1)}";

\tprotected async validate(entity: ${model.name}Attributes): Promise<void> {
${validations}
\t}
}`.trim();

    if (fs.existsSync(serviceFile)) {
      const existing = fs.readFileSync(serviceFile, "utf-8");
      const { body } = extractCommentAndBody(existing);

      if (body === newBody) {
        console.log(`No changes: ${model.name}`);
        continue;
      }
    }

    const fullContent = `${getTimestampComment()}\n${newBody}`;
    fs.writeFileSync(serviceFile, fullContent);
    console.log(
      `${fs.existsSync(serviceFile) ? "Updated" : "Created"}: ${model.name}`,
    );

    relationships
      .filter((r: any) => r.model === model.name)
      .forEach((r: any) => console.log(r));
  }
}

async function generateIndexFile(models: any) {
  const directory = path.resolve(__dirname, "../services/repository");
  const indexFile = path.resolve(directory, "index.ts");

  const imports: string[] = [];
  const exports: string[] = [];
  const instances: string[] = [];

  models
    .sort((a: any, b: any) => a.name.localeCompare(b.name))
    .forEach((model: any) => {
      const kebabName = toKebabCase(model.name);
      const modelNameLower
      = model.name.charAt(0).toLowerCase() + model.name.slice(1);

      imports.push(
        `import { ${model.name}Service } from "./${kebabName}.service";`,
      );
      exports.push(`export { ${model.name}Service };`);
      instances.push(
        `export const ${modelNameLower}Service = new ${model.name}Service();`,
      );
    });

  const newBody = `${imports.join("\n")}

${exports.join("\n")}

${instances.join("\n")}`.trim();

  let existingBody = null;
  if (fs.existsSync(indexFile)) {
    const existing = fs.readFileSync(indexFile, "utf-8");
    const { body } = extractCommentAndBody(existing);
    existingBody = body;
    if (existingBody === newBody) {
      console.log("No changes to index file");
      return;
    }
  }

  const fullContent = `${getTimestampComment()}\n${newBody}`;
  fs.writeFileSync(indexFile, fullContent);
  console.log("Updated index file");
}

async function updateMCPConfig(models: any) {
  const mcpConfigFile = path.resolve(__dirname, "../config/mcp-config.ts");

  if (!fs.existsSync(mcpConfigFile)) {
    console.log("MCP config file does not exist, skipping update");
    return;
  }

  const serviceImports: string[] = [];
  const serviceMapEntries: string[] = [];
  const schemaEntries: string[] = [];

  models
    .sort((a: any, b: any) => a.name.localeCompare(b.name))
    .forEach((model: any) => {
      const kebabName = toKebabCase(model.name);
      const modelNameLower = model.name.charAt(0).toLowerCase() + model.name.slice(1);

      serviceImports.push(`  ${modelNameLower}Service,`);
      serviceMapEntries.push(`  "${kebabName}": ${modelNameLower}Service,`);

      // Extract just the essential field info for JSON schema
      const fields = model.fields.reduce((acc: any, field: any) => {
        if (field.kind === "scalar" || field.kind === "enum") {
          acc[field.name] = {
            type: field.type.toLowerCase(),
            required: field.isRequired,
            ...(field.isList && { isList: true }),
            ...(field.hasDefaultValue && { hasDefault: true }),
          };
        }
        return acc;
      }, {});

      const schemaString = JSON.stringify(fields, null, 2)
        .split("\n")
        .map((line, i) => i === 0 ? line : `    ${line}`)
        .join("\n");

      schemaEntries.push(`  { 
    name: "${kebabName}", 
    description: "Schema for ${model.name} entity",
    schema: ${schemaString}
  },`);
    });

  let content = fs.readFileSync(mcpConfigFile, "utf-8");

  // Update imports
  const newImport = `import {
${serviceImports.join("\n")}
} from "../services/repository";`;

  content = content.replace(
    /import\s*\{[\s\S]*?\}\s*from\s*"\.\.\/services\/repository";/,
    newImport,
  );

  // Update service map
  const newServiceMap = `const serviceMap: Record<string, any> = {
${serviceMapEntries.join("\n")}
};`;

  content = content.replace(
    /const serviceMap: Record<string, any> = \{[\s\S]*?\};/,
    newServiceMap,
  );

  // Update schemas
  const newSchemas = `export const SCHEMAS: ISchema[] = [
${schemaEntries.join("\n")}
];`;

  content = content.replace(
    /export const SCHEMAS: ISchema\[\] = \[[\s\S]*?\];/,
    newSchemas,
  );

  fs.writeFileSync(mcpConfigFile, content);
  console.log("Updated MCP config service map and schemas");
}

async function main() {
  const models = await getModels();
  const relationships = await getRelationships(models);
  await generateServiceFiles(models, relationships);
  await generateIndexFile(models);
  await updateMCPConfig(models);
}

main();
